{"test_cases_lookup_map": {"{\"actual_output\": \"Response for question 1\", \"context\": null, \"expected_output\": null, \"hyperparameters\": null, \"input\": \"When was the Rhodes Statue built?\", \"retrieval_context\": [\"Context for question 1\"]}": {"cached_metrics_data": [{"metric_metadata": {"metric": "Faithfulness", "threshold": 0.0, "success": true, "score": 1.0, "reason": "The score is 1.00 because there are no contradictions, indicating that the actual output is perfectly aligned with the information presented in the retrieval context.", "strictMode": false, "evaluationModel": "gpt-4", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.0, "evaluation_model": "gpt-4", "strict_mode": false, "include_reason": true}}]}, "{\"actual_output\": \"Response for question 2\", \"context\": null, \"expected_output\": null, \"hyperparameters\": null, \"input\": \"Where is the Pyramid of Giza\", \"retrieval_context\": [\"Context for question 2\"]}": {"cached_metrics_data": [{"metric_metadata": {"metric": "Faithfulness", "threshold": 0.0, "success": true, "score": 1.0, "reason": "The score is 1.00 because there are no contradictions present, indicating perfect alignment between the actual output and the retrieval context.", "strictMode": false, "evaluationModel": "gpt-4", "evaluationCost": 0}, "metric_configuration": {"threshold": 0.0, "evaluation_model": "gpt-4", "strict_mode": false, "include_reason": true}}]}}}