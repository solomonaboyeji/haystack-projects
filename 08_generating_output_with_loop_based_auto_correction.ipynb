{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Structured Output with Loop-Based Auto Correction\n",
    "\n",
    "Build a System that extracts unstructured data, puts it in a JSON schema and automatically corrects errors in the JSON output from a large language model (LLM) to make sure it follows the specified structure.\n",
    "\n",
    "#### Loops in Pipelines\n",
    "Components in a pipeline can work in an iterative loops, which you can cap at a desired number. This can be handy for self-correcting loops, where a generator produces some output and then a validator component to check if the output is correct.\n",
    "\n",
    "The notebook uses OpenAI gpt-3.5-turbo model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"canals.pipeline.pipeline\").setLevel(logging.DEBUG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define Schema to Parse the JSON object\n",
    "\n",
    "A pydantic class to define the schema of the data we want to extract from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class City(BaseModel):\n",
    "    name: str\n",
    "    country: str\n",
    "    population: int\n",
    "    \n",
    "class CitiesData(BaseModel):\n",
    "    cities: List[City]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_schema = CitiesData.model_json_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Custom Component: OutputValidator\n",
    "OutputValidator is a custom component that validates if the JSON Object the LLM generates compiles with the provided Pydantic Model. IF it doesn't, OutputValidator returns an error message along with the incorrect JSON object to get it fixed in the next loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import pydantic\n",
    "from pydantic import ValidationError\n",
    "from typing import Optional, List\n",
    "from colorama import Fore\n",
    "from haystack import component\n",
    "\n",
    "# Define the component input parameters\n",
    "@component\n",
    "class OutputValidator:\n",
    "    def __init__(self, pydantic_model: pydantic.BaseModel):\n",
    "        self.pydantic_model = pydantic_model\n",
    "        self.iteration_counter = 0\n",
    "\n",
    "    # Define the component output\n",
    "    @component.output_types(valid_replies=List[str], invalid_replies=Optional[List[str]], error_message=Optional[str])\n",
    "    def run(self, replies: List[str]):\n",
    "\n",
    "        self.iteration_counter += 1\n",
    "\n",
    "        ## Try to parse the LLM's reply ##\n",
    "        # If the LLM's reply is a valid object, return `\"valid_replies\"`\n",
    "        try:\n",
    "            output_dict = json.loads(replies[0])\n",
    "            self.pydantic_model.parse_obj(output_dict)\n",
    "            print(\n",
    "                Fore.GREEN\n",
    "                + f\"OutputValidator at Iteration {self.iteration_counter}: Valid JSON from LLM - No need for looping: {replies[0]}\"\n",
    "            )\n",
    "            return {\"valid_replies\": replies}\n",
    "\n",
    "        # If the LLM's reply is corrupted or not valid, return \"invalid_replies\" and the \"error_message\" for LLM to try again\n",
    "        except (ValueError, ValidationError) as e:\n",
    "            print(\n",
    "                Fore.RED\n",
    "                + f\"OutputValidator at Iteration {self.iteration_counter}: Invalid JSON from LLM - Let's try again.\\n\"\n",
    "                f\"Output from LLM:\\n {replies[0]} \\n\"\n",
    "                f\"Error from OutputValidator: {e}\"\n",
    "            )\n",
    "            return {\"invalid_replies\": replies, \"error_message\": str(e)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_validator = OutputValidator(pydantic_model=CitiesData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Prompt\n",
    "\n",
    "An instruction to the LLM for converting a passage into a JSON format. Ensure the instructions explain how to identify and correct errors if the JSON doesn't match the required schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.builders import PromptBuilder\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Create a JSON object from the information present in this passage: {{passage}}.\n",
    "Only use information that is present in the passage. Follow this JSON schema, but only return the actual instances without any additional schema definition:#\n",
    "{{schema}}\n",
    "Make sure your response is a dict and not a list.\n",
    "{% if invalid_replies and error_message %}\n",
    "    You already created the following output in a previous attempt: {{invalid_replies}}\n",
    "    However, this doesn't comply with the format requirements above and triggered this Python exception: {{error_message}}\n",
    "    Correct the output and try again. Just return the corrected output without any extra explanations.\n",
    "{% endif %}\n",
    "\"\"\"\n",
    "\n",
    "prompt_builder = PromptBuilder(template=prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise ValueError(\"OPENAI_API_KEY is required.\")\n",
    "\n",
    "generator = OpenAIGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Pipeline\n",
    "\n",
    "Add all components to the pipeline and connect them.\n",
    "\n",
    "Add connections from output_validator back to the prompt_builder for cases where the produced JSON doesn't comply with the JSON schema. Set max_loops_allowed to avoid infinite looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7709f7a3c6d0>\n",
       "ðŸš… Components\n",
       "  - prompt_builder: PromptBuilder\n",
       "  - llm: OpenAIGenerator\n",
       "  - output_validator: OutputValidator\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - prompt_builder.prompt -> llm.prompt (str)\n",
       "  - llm.replies -> output_validator.replies (List[str])\n",
       "  - output_validator.invalid_replies -> prompt_builder.invalid_replies (Optional[List[str]])\n",
       "  - output_validator.error_message -> prompt_builder.error_message (Optional[str])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack import Pipeline\n",
    "\n",
    "pipeline = Pipeline(max_loops_allowed=5)\n",
    "\n",
    "# Add components to your pipeline\n",
    "pipeline.add_component(instance=prompt_builder, name=\"prompt_builder\")\n",
    "pipeline.add_component(instance=generator, name=\"llm\")\n",
    "pipeline.add_component(instance=output_validator, name=\"output_validator\")\n",
    "\n",
    "# Now, connect the components to each other\n",
    "pipeline.connect(\"prompt_builder\", \"llm\")\n",
    "pipeline.connect(\"llm\",  \"output_validator\")\n",
    "# If a component has more than one output or input, explicitly specify the connections:\n",
    "pipeline.connect(\"output_validator.invalid_replies\", \"prompt_builder.invalid_replies\")\n",
    "pipeline.connect(\"output_validator.error_message\", \"prompt_builder.error_message\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.draw(\"auto-correct-pipeline.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(json_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mOutputValidator at Iteration 2: Valid JSON from LLM - No need for looping: {\n",
      "    \"cities\": [\n",
      "        {\n",
      "            \"name\": \"Berlin\",\n",
      "            \"country\": \"Germany\",\n",
      "            \"population\": 3850809\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Paris\",\n",
      "            \"country\": \"France\",\n",
      "            \"population\": 2161000\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Lisbon\",\n",
      "            \"country\": \"Portugal\",\n",
      "            \"population\": 504718\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "passage = \"Berlin is the capital of Germany. It has a population of 3,850,809. Paris, France's capital, has 2.161 million residents. Lisbon is the capital and the largest city of Portugal with the population of 504,718.\"\n",
    "result = pipeline.run({\"prompt_builder\": {\"passage\": passage, \"schema\": json_schema}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cities': [{'name': 'Berlin', 'country': 'Germany', 'population': 3850809}, {'name': 'Paris', 'country': 'France', 'population': 2161000}, {'name': 'Lisbon', 'country': 'Portugal', 'population': 504718}]}\n"
     ]
    }
   ],
   "source": [
    "valid_reply = result[\"output_validator\"][\"valid_replies\"][0]\n",
    "valid_json = json.loads(valid_reply)\n",
    "print(valid_json)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
