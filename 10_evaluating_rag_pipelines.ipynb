{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating RAG pipelines\n",
    "\n",
    "This section will be divided into 2:\n",
    "\n",
    "1. Part A: Deep Explanation\n",
    "2. Part B: Deep Explanation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A: Deep Explanation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haystack provides a wide range of Evaluators which can perform 2 types of evaluations:\n",
    "\n",
    "1. Model-Based Evaluation\n",
    "2. Statistical Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Model-Based Evaluation\n",
    "\n",
    "Model-based evaluation uses a language model to check the results of a Pipeline using a Language Model to check the results of a Pipeline.\n",
    "\n",
    "##### Using LLM for Evaluation\n",
    "\n",
    "A golden large language model will be used for this evaluation. The golden large language model such as OpenAI's GPT models, GPT-4, is utilize to evaluate a RAG pipeline by providing it with the Pipeline's results and sometimes additional information, along with a prompt that outlines the evaluation criteria.\n",
    "This does not need labels for the outputs, and it is easy to use.\n",
    "\n",
    "The method of using LLM as an evaluator is very flexible as it exposes a number of metrics to us. Each metrics is ultimately a well-crafted prompt describing to the LLM how to evaluate and score results.\n",
    "\n",
    "Common Metrics includes:\n",
    "\n",
    "1. Faithfulness\n",
    "2. Context Relevance\n",
    "\n",
    "##### Small Cross-Encoder Models for Evaluation\n",
    "\n",
    "Alongside LLMs for evaluation, we can use small cross-encoder models. These models can calculate, for example , semantic answer similarity. In contrast to metrics based on LLMs, as the metrics based on smaller models don't require an API key of a model provider.\n",
    "\n",
    "This method is faster and cheaper to run but it is less flexible in terms of what aspect you can evaluate. You can only evaluate what the small model was trained to evaluate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model-Based Evaluation Pipelines in Haystack\n",
    "\n",
    "There are two ways of performing model-based evaluation in Haystack, both of which leverage Pipelien and Evaluator Components\n",
    "\n",
    "1. Create and run an Evaluation Pipeline independently. This means you will have to provide the required inputs to the evaluation Pipeline manually. This is recommend because we can store the results of our RAG pipeline and try out different evaluation metrics afterward without needing to re-run the RAG pipeline every time.\n",
    "\n",
    "2. Add Evaluator Component to the end of the RAG pipeline. This means we run both the RAG Pipeline and the Evaluation on of it in a single pipeline.run() call.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model-based Evaluation of Retrieved Documents\n",
    "\n",
    "##### ContextRelevantEvaluator\n",
    "\n",
    "This evaluator uses an LLM to evaluate whether contexts are relevant to a question. It does not require ground truth labels.\n",
    "\n",
    "The component breaks up the context into multiple statements and checks whether each statement is relevant for answering a question. The final score for the context relevance is a number from 0.0 to 1.0 and represents the proportion of statements that are relevant to the provided question.\n",
    "\n",
    "You can pass an example to the evaluator which are sent as few-prompts to the LLM\n",
    "\n",
    "```\n",
    "[{\n",
    "\t\"inputs\": {\n",
    "\t\t\"questions\": \"What is the capital of Italy?\", \"contexts\": [\"Rome is the capital of Italy.\"],\n",
    "\t},\n",
    "\t\"outputs\": {\n",
    "\t\t\"statements\": [\"Rome is the capital of Italy.\", \"Rome has more than 4 million inhabitants.\"],\n",
    "\t\t\"statement_scores\": [1, 0],\n",
    "\t},\n",
    "}]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usage\n",
    "\n",
    "A. On its own\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/solomon/Documents/projects/AI/learning_haystack/env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What makes both Python and Javascript excellent?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "[0.5]\n",
      "[{'statements': ['Python, created by Guido van Rossum in the late 1980s, is a high-level general-purpose programming language. Its design philosophy emphasizes code readability, and its language constructs aim to help programmers write clear, logical code for both small and large-scale software projects.', 'Javascript and Python both have received a lot backlashes but yet keeps waxing strong.'], 'statement_scores': [1, 0], 'score': 0.5}]\n",
      "\n",
      "\n",
      "\n",
      "Question:  Who created the Python Language\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[1.0]\n",
      "[{'statements': ['Python, created by Guido van Rossum in the late 1980s, is a high-level general-purpose programming language.'], 'statement_scores': [1], 'score': 1.0}]\n",
      "\n",
      "\n",
      "\n",
      "Question:  What are people's feelings towards Javascript?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[1.0]\n",
      "[{'statements': ['Javascript and Python both have received a lot backlashes but yet keeps waxing strong.'], 'statement_scores': [1], 'score': 1.0}]\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from haystack.components.evaluators import ContextRelevanceEvaluator\n",
    "\n",
    "questions = [\n",
    "    \"What makes both Python and Javascript excellent?\",\n",
    "    \"Who created the Python Language\",\n",
    "    \"What are people's feelings towards Javascript?\",\n",
    "]\n",
    "contexts = [\n",
    "    [\n",
    "        \"Python, created by Guido van Rossum in the late 1980s, is a high-level general-purpose programming language. Its design philosophy emphasizes code readability, and its language constructs aim to help programmers write clear, logical code for both small and large-scale software projects.\",\n",
    "        \"Javascript and Python both have received a lot backlashes but yet keeps waxing strong.\",\n",
    "    ]\n",
    "]\n",
    "for question in questions:\n",
    "    print(\"Question: \", question)\n",
    "    # OpenAI is the only supported model\n",
    "    evaluator = ContextRelevanceEvaluator(raise_on_failure=True)\n",
    "    result = evaluator.run(questions=[question], contexts=contexts)\n",
    "\n",
    "    print(result[\"score\"])\n",
    "    print(result[\"individual_scores\"])\n",
    "\n",
    "    # Notice the statement_score\n",
    "    print(result[\"results\"])\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. In a Pipeline\n",
    "\n",
    "In this example, we use the ContextRelevanceEvaluator and the FaithfulnessEvaluator together in a pipeline to evaluate responses and context (in the content of documents) recieved by a RAG pipeline based on the provided questionst.\n",
    "\n",
    "This is an example of how we can run multiple metrics after we receive the context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Individual Scores\n",
      "context_relevance_evaluator  =>  [1.0]\n",
      "Statement:\n",
      "['Python, created by Guido van Rossum in the late 1980s.']\n",
      "faithfulness_evaluator  =>  [0.5]\n",
      "Statement:\n",
      "['Python is a high-level general-purpose programming language.', 'Python was created by Guido van Rossum in the late 1980s.']\n",
      "\n",
      "Score\n",
      "context_relevance_evaluator  =>  1.0\n",
      "Statement:\n",
      "['Python, created by Guido van Rossum in the late 1980s.']\n",
      "faithfulness_evaluator  =>  0.5\n",
      "Statement:\n",
      "['Python is a high-level general-purpose programming language.', 'Python was created by Guido van Rossum in the late 1980s.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.components.evaluators import (\n",
    "    ContextRelevanceEvaluator,\n",
    "    FaithfulnessEvaluator,\n",
    ")\n",
    "\n",
    "pipeline = Pipeline()\n",
    "context_relevance_evaluator = ContextRelevanceEvaluator()\n",
    "faithfulness_evaluator = (\n",
    "    FaithfulnessEvaluator()\n",
    ")  # evaluates generated/extracted answers, more on this in the next secion\n",
    "pipeline.add_component(\"context_relevance_evaluator\", context_relevance_evaluator)\n",
    "pipeline.add_component(\"faithfulness_evaluator\", faithfulness_evaluator)\n",
    "\n",
    "questions = [\"Who created the Python Language?\"]\n",
    "contexts = [\n",
    "    [\n",
    "        \"Python, created by Guido van Rossum in the late 1980s, is a high-level general-purpose programming language. Its design philosophy emphasizes code readability, and its language constructs aim to help programmers write clear, logical code for both small and large-scale software projects.\"\n",
    "    ],\n",
    "]\n",
    "predicted_answers = [\n",
    "    \"Python is a high-level general-purpose programming language that was created by George Lucas\"\n",
    "]\n",
    "\n",
    "result = pipeline.run(\n",
    "    {\n",
    "        \"context_relevance_evaluator\": {\"questions\": questions, \"contexts\": contexts},\n",
    "        \"faithfulness_evaluator\": {\n",
    "            \"questions\": questions,\n",
    "            \"contexts\": contexts,\n",
    "            \"predicted_answers\": predicted_answers,\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"\\nIndividual Scores\")\n",
    "for evaluator in result:\n",
    "    print(evaluator, \" => \", result[evaluator][\"individual_scores\"])\n",
    "    print(\"Statement:\")\n",
    "    for ev_result in result[evaluator][\"results\"]:\n",
    "        print(ev_result[\"statements\"])\n",
    "\n",
    "print(\"\\nScore\")\n",
    "for evaluator in result:\n",
    "    print(evaluator, \" => \", result[evaluator][\"score\"])\n",
    "    print(\"Statement:\")\n",
    "    for ev_result in result[evaluator][\"results\"]:\n",
    "        print(ev_result[\"statements\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model-based Evaluation of Generated or Extracted Answers\n",
    "\n",
    "##### FaithfulnessEvaluator (aka groundedness)\n",
    "\n",
    "This uses an LLM to evaluate whether a generated answer can be inferred from the provided contexts. It does not require ground truth labels.\n",
    "\n",
    "The metric is sometimes called groundedness or hallucination.\n",
    "\n",
    "FaithfulnessEvaluator component can be used to evaluate documents retrieved by a Haystack pipeline, such as RAG pipeline, without ground truth labels.\n",
    "\n",
    "The component splits the generated answer into statements and checks each of them against the provided context, with an LLM. A higher faithfulness score is better, and it indicates that a larger number of statements in the generated answers can be inferred from the contexts.\n",
    "\n",
    "This score can be used to better understand how often and when the Generator in a RAG pipeline hallucinates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usage\n",
    "\n",
    "A. On its own\n",
    "\n",
    "An example of using a FaithfulnessEvaluator component to evaluate a predicted answer generated based on a provided question and context. It returned a score of 0.5 because it detects two statements in the answer, of which only one is correct.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5]\n",
      "0.5\n",
      "[{'statements': ['Python is a high-level general-purpose programming language.', 'Python was created by Guido van Rossum in the late 1980s.'], 'statement_scores': [1, 0], 'score': 0.5}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from haystack.components.evaluators import FaithfulnessEvaluator\n",
    "\n",
    "questions = [\"Who created the Python language?\"]\n",
    "contexts = [\n",
    "    [\n",
    "        \"Python, created by Guido van Rossum in the late 1980s, is a high-level general-purpose programming language. Its design philosophy emphasizes code readability, and its language constructs aim to help programmers write clear, logical code for both small and large-scale software projects.\"\n",
    "    ],\n",
    "]\n",
    "predicted_answers = [\n",
    "    \"Python is a high-level general-purpose programming language that was created by George Lucas.\"\n",
    "]\n",
    "evaluator = FaithfulnessEvaluator()\n",
    "result = evaluator.run(\n",
    "    questions=questions, contexts=contexts, predicted_answers=predicted_answers\n",
    ")\n",
    "\n",
    "print(result[\"individual_scores\"])\n",
    "\n",
    "print(result[\"score\"])\n",
    "\n",
    "print(result[\"results\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. In a Pipeline\n",
    "\n",
    "As shown in the ContextRelevanceEvaluator.\n",
    "Skipping this to avoid excessive usage of credits.\n",
    "\n",
    "// NO CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SASEvaluator (Semantic Answer Similarity)\n",
    "\n",
    "SASEvaluator evaluates answers predicted by pipelines using ground truth labels. It checks the semantic similarity of a predicted answer and the ground truth answer using a fine-tuned language model. The metric is called Semantic Answer Similarity.\n",
    "\n",
    "The evaluator uses a bi-encoder or a cross-encoder model. By default it uses the `sentence-transformers/paraphrase-multilingual-mpnet-base-v2` mode.\n",
    "\n",
    "NOTE: Only one predicted answer is compared to one ground truth answer at a time. The component does not support multiple ground truth answers for the same question or multiple answers predicted for the same question.\n",
    "\n",
    "https://arxiv.org/abs/2108.06130\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usage\n",
    "\n",
    "A. On its own\n",
    "\n",
    "The example below compares two answers and compare them to ground truth answers. We need to call the `warm_up()` before `run()` to load the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9999999403953552, 0.5174765586853027]\n",
      "0.758738249540329\n"
     ]
    }
   ],
   "source": [
    "from haystack.components.evaluators import SASEvaluator\n",
    "\n",
    "# model is from huggingface\n",
    "sas_evaluator = SASEvaluator()\n",
    "sas_evaluator.warm_up()\n",
    "result = sas_evaluator.run(\n",
    "    ground_truth_answers=[\"Berlin\", \"Paris\"], predicted_answers=[\"Berlin\", \"Lyon\"]\n",
    ")\n",
    "print(result[\"individual_scores\"])\n",
    "\n",
    "print(result[\"score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. In a Pipeline\n",
    "\n",
    "Below is an example where we use an `AnswerExactMatchEvaluator` and a `SASEvaluator` in a pipeline to evaluate two answers and compare them to a ground truth answesr.\n",
    "\n",
    "Running a pipeline instead of the individual components simplifies calculating more than one metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Individual Scores\n",
      "[1, 0]\n",
      "[0.9999999403953552, 0.5174765586853027]\n",
      "\n",
      "Score\n",
      "0.5\n",
      "0.758738249540329\n"
     ]
    }
   ],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.components.evaluators import AnswerExactMatchEvaluator, SASEvaluator\n",
    "\n",
    "pipeline = Pipeline()\n",
    "em_evaluator = AnswerExactMatchEvaluator()\n",
    "sas_evaluator = SASEvaluator()\n",
    "\n",
    "pipeline.add_component(\"em_evaluator\", em_evaluator)\n",
    "pipeline.add_component(\"sas_evaluator\", sas_evaluator)\n",
    "\n",
    "\n",
    "ground_truth_answers = [\"Berlin\", \"Paris\"]\n",
    "predicted_answers = [\"Berlin\", \"Lyon\"]\n",
    "\n",
    "result = pipeline.run(\n",
    "    {\n",
    "        \"em_evaluator\": {\n",
    "            \"ground_truth_answers\": ground_truth_answers,\n",
    "            \"predicted_answers\": predicted_answers,\n",
    "        },\n",
    "        \"sas_evaluator\": {\n",
    "            \"ground_truth_answers\": ground_truth_answers,\n",
    "            \"predicted_answers\": predicted_answers,\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\nIndividual Scores\")\n",
    "\n",
    "for evaluator in result:\n",
    "    print(result[evaluator][\"individual_scores\"])\n",
    "\n",
    "print(\"\\nScore\")\n",
    "\n",
    "for evaluator in result:\n",
    "    print(result[evaluator][\"score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RagasEvaluator\n",
    "\n",
    "RAGAS is a framework that helps you evaluate RAG pipelines.\n",
    "\n",
    "Learn more about RAGAS here: https://docs.ragas.io/en/latest/index.html\n",
    "\n",
    "Supported Metrics\n",
    "\n",
    "- `ANSWER_CORRECTNESS`: grades the accuracy of the generated answer when compared to the ground truth.\n",
    "- `FAITHFULNESS`: grades how factual the generated response was.\n",
    "- `ANSWER_SIMILARITY`: grades how similar the generated answer is to the ground truth answer specified.\n",
    "- `CONTEXT_PRECISION`: grades if the answer has any additional irrelevant information for the question asked.\n",
    "- `CONTEXT_UTILIZATION`: grade to what extent the generated answer uses the provided context\n",
    "- `CONTEXT_RECALL`: grades how complete the generated response was for the question specified\n",
    "- `ASPECT_CRITIQUE`: grades generated answers based on custom aspects on a binary scale\n",
    "- `CONTEXT_RELEVANCY`: grades how irrelevant the provided context was for the question specified\n",
    "- `ANSWER_RELEVANCY`: grades how relevant the generated response is given the question.\n",
    "\n",
    "Models Supported includes:\n",
    "\n",
    "- All GPT models from OpenAI\n",
    "- Google VertexAI Models\n",
    "- Azure OpenAI Models\n",
    "- Amazon Bedrock Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usage\n",
    "\n",
    "1. You can use the `RagasEvaluator` while providing correct `metric_params` for the metric you are using.\n",
    "2. Run the `RagasEvaluator`, either on its own or in a pipeline, by providing the expected input for the metric you are using.\n",
    "\n",
    "##### Examples\n",
    "\n",
    "##### Evaluate Context Relevance\n",
    "\n",
    "Create a context-relevance evaluation pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00,  3.32it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'evaluator': {'results': [[{'name': 'context_relevancy', 'score': 1.0}],\n",
       "   [{'name': 'context_relevancy', 'score': 1.0}]]}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack_integrations.components.evaluators.ragas import (\n",
    "    RagasEvaluator,\n",
    "    RagasMetric,\n",
    ")\n",
    "\n",
    "pipeline = Pipeline()\n",
    "evaluator = RagasEvaluator(metric=RagasMetric.CONTEXT_RELEVANCY)\n",
    "pipeline.add_component(\"evaluator\", evaluator)\n",
    "\n",
    "\n",
    "# send this data into the evaluator\n",
    "results = pipeline.run(\n",
    "    {\n",
    "        \"evaluator\": {\n",
    "            \"questions\": [\n",
    "                \"When was the Rhodes Statue built?\",  # question 1\n",
    "                \"Where is the Pyramid of Giza\",  # question 2\n",
    "            ],\n",
    "            \"contexts\": [\n",
    "                [\"Context for question 1\"],  # context for question 1\n",
    "                [\"Context for question 2\"],  # context for question 1\n",
    "            ],\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate Relevance and Aspect Critique\n",
    "\n",
    "Create a context-relevance and aspect critique evaluation pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack_integrations.components.evaluators.ragas import (\n",
    "    RagasEvaluator,\n",
    "    RagasMetric,\n",
    ")\n",
    "\n",
    "pipeline = Pipeline()\n",
    "evaluator_context = RagasEvaluator(metric=RagasMetric.CONTEXT_PRECISION)\n",
    "evaluator_aspect = RagasEvaluator(\n",
    "    metric=RagasMetric.ASPECT_CRITIQUE,\n",
    "    metric_params={\n",
    "        \"name\": \"valid_for_children\",\n",
    "        \"definition\": \"Is this answer problematic for children?\",\n",
    "        \"strictness\": 3,\n",
    "    },\n",
    ")\n",
    "pipeline.add_component(\"evaluator_context\", evaluator_context)\n",
    "pipeline.add_component(\"evaluator_aspect\", evaluator_aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 2/2 [00:01<00:00,  1.70it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:01<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'evaluator_aspect': {'results': [[{'name': 'valid_for_children', 'score': 1}],\n",
      "                                  [{'name': 'valid_for_children',\n",
      "                                    'score': 0}]]},\n",
      " 'evaluator_context': {'results': [[{'name': 'context_precision',\n",
      "                                     'score': 0.9999999999}],\n",
      "                                   [{'name': 'context_precision',\n",
      "                                     'score': 0.9999999999}]]}}\n"
     ]
    }
   ],
   "source": [
    "QUESTIONS = [\n",
    "    \"Which is the most popular global sport?\",\n",
    "    \"Who created the Python language?\",\n",
    "]\n",
    "CONTEXTS = [\n",
    "    [\n",
    "        \"The popularity of sports can be measured in various ways, including TV viewership, social media presence, number of participants, and economic impact. Football is undoubtedly the world's most popular sport with major events like the FIFA World Cup and sports personalities like Ronaldo and Messi, drawing a followership of more than 4 billion people.\"\n",
    "    ],\n",
    "    [\n",
    "        \"Python, created by Guido van Rossum in the late 1980s, is a high-level general-purpose programming language. Its design philosophy emphasizes code readability, and its language constructs aim to help programmers write clear, logical code for both small and large-scale software projects.\"\n",
    "    ],\n",
    "]\n",
    "RESPONSES = [\n",
    "    \"Football is the most popular sport with around 4 billion followers worldwide\",\n",
    "    \"Python language was created by Guido van Rossum.\",\n",
    "]\n",
    "GROUND_TRUTHS = [\n",
    "    \"Football is the most popular sport\",\n",
    "    \"Python language was created by Guido van Rossum.\",\n",
    "]\n",
    "\n",
    "results = pipeline.run(\n",
    "    {\n",
    "        \"evaluator_context\": {\n",
    "            \"questions\": QUESTIONS,\n",
    "            \"contexts\": CONTEXTS,\n",
    "            \"ground_truths\": GROUND_TRUTHS,\n",
    "        },\n",
    "        \"evaluator_aspect\": {\n",
    "            \"questions\": QUESTIONS,\n",
    "            \"contexts\": CONTEXTS,\n",
    "            \"responses\": RESPONSES,\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "import pprint\n",
    "\n",
    "pprint.pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DeepEvalEvaluator\n",
    "\n",
    "DeepEval is a simple-to-use, open-source LLM evaluation framework. It is similar to Pytest but specialized for unit testing LLM outputs. DeepEval incorporates the latest research to evaluate LLM outputs based on metrics such as G-Eval, hallucination, answer relevancy, RAGAS, etc., which uses LLMs and various other NLP models that runs locally on your machine for evaluation.\n",
    "\n",
    "DeepEval gives you additional options of using models on your machine.\n",
    "https://docs.confident-ai.com/docs/metrics-introduction#using-a-custom-llm\n",
    "\n",
    "Integrate into CI/CDs.\n",
    "\n",
    "Supported Metrics:\n",
    "\n",
    "- `ANSWER_RELEVANCY`: grades how relevant the answer was to the question specified\n",
    "- `FAITHFULNESS`: grades how factual the generated response was.\n",
    "- `CONTEXTUAL_PRECISION`: grades if he answer has any additional irrelevant information for the question asked.\n",
    "- `CONTEXTUAL_RECALL`: grades how complete the generated response was for the question specified\n",
    "- `CONTEXTUAL_RELEVANCE`: grades how relevant provided context was for the question specified\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usage\n",
    "\n",
    "1. You can use the `DeepEvalEvaluator` while providing correct `metric_params` for the metric you are using.\n",
    "2. Run the `DeepEvalEvaluator`, either on its own or in a pipeline, by providing the expected input for the metric you are using.\n",
    "\n",
    "##### Examples\n",
    "\n",
    "##### Evaluate Faithfulness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/solomon/Documents/projects/AI/learning_haystack/env/lib/python3.11/site-packages/rich/live.py:231: \n",
       "UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/solomon/Documents/projects/AI/learning_haystack/env/lib/python3.11/site-packages/rich/live.py:231: \n",
       "UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/solomon/Documents/projects/AI/learning_haystack/env/lib/python3.11/site-packages/rich/live.py:231: \n",
       "UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/solomon/Documents/projects/AI/learning_haystack/env/lib/python3.11/site-packages/rich/live.py:231: \n",
       "UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test cases...\n",
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/solomon/Documents/projects/AI/learning_haystack/env/lib/python3.11/site-packages/rich/live.py:231: \n",
       "UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/solomon/Documents/projects/AI/learning_haystack/env/lib/python3.11/site-packages/rich/live.py:231: \n",
       "UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/solomon/Documents/projects/AI/learning_haystack/env/lib/python3.11/site-packages/rich/live.py:231: \n",
       "UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/solomon/Documents/projects/AI/learning_haystack/env/lib/python3.11/site-packages/rich/live.py:231: \n",
       "UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/solomon/Documents/projects/AI/learning_haystack/env/lib/python3.11/site-packages/portalocker/utils.py:218: UserWarning: timeout has no effect in blocking mode\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/solomon/Documents/projects/AI/learning_haystack/env/lib/python3.11/site-packages/rich/live.py:231: \n",
       "UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/solomon/Documents/projects/AI/learning_haystack/env/lib/python3.11/site-packages/rich/live.py:231: \n",
       "UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ✅ Faithfulness (score: 1, threshold: 0.0, strict: False, evaluation model: gpt-4, reason: The score is 1.00 because there are no contradictions, indicating that the actual output is perfectly aligned with the information presented in the retrieval context., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: When was the Rhodes Statue built?\n",
      "  - actual output: Response for question 1\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: ['Context for question 1']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ✅ Faithfulness (score: 1, threshold: 0.0, strict: False, evaluation model: gpt-4, reason: The score is 1.00 because there are no contradictions present, indicating perfect alignment between the actual output and the retrieval context., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Where is the Pyramid of Giza\n",
      "  - actual output: Response for question 2\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: ['Context for question 2']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "FaithfulnessMetric: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/solomon/Documents/projects/AI/learning_haystack/env/lib/python3.11/site-packages/portalocker/utils.py:218: UserWarning: timeout has no effect in blocking mode\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Tests finished! Run <span style=\"color: #008000; text-decoration-color: #008000\">\"deepeval login\"</span> to view evaluation results on the web.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✅ Tests finished! Run \u001b[32m\"deepeval login\"\u001b[0m to view evaluation results on the web.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack_integrations.components.evaluators.deepeval import (\n",
    "    DeepEvalEvaluator,\n",
    "    DeepEvalMetric,\n",
    ")\n",
    "\n",
    "pipeline = Pipeline()\n",
    "evaluator = DeepEvalEvaluator(\n",
    "    metric=DeepEvalMetric.FAITHFULNESS, metric_params={\"model\": \"gpt-4\"}\n",
    ")\n",
    "pipeline.add_component(\"evaluator\", evaluator)\n",
    "\n",
    "results = pipeline.run(\n",
    "    {\n",
    "        \"evaluator\": {\n",
    "            \"questions\": [\n",
    "                \"When was the Rhodes Statue built?\",\n",
    "                \"Where is the Pyramid of Giza\",\n",
    "            ],\n",
    "            \"contexts\": [[\"Context for question 1\"], [\"Context for question 2\"]],\n",
    "            \"responses\": [\"Response for question 1\", \"Response for question 2\"],\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical Evaluation Pipelines in Haystack\n",
    "\n",
    "Statistical Evaluation compares ground truth labels with pipeline predictions, typically using metrics such as precision or recall.\n",
    "\n",
    "Here the ground truth labels of expected answers are compared to the pipeline's prediction. Mostly use this with Extractive Models. For assessing answers generated by an LLM, it is recommended we use the model-based evaluation instead, as it can incorporate measures of semantic similarity or coherence and is better suited to evaluate predictions that might differe in wording from the ground truth labels\n",
    "\n",
    "##### Statistical Evalution of Retrieved Documents\n",
    "\n",
    "##### DocumentRecallEvaluator\n",
    "\n",
    "Recall measures how often the correct document was among the retrieved documents over a set of queries.\n",
    "\n",
    "The evaluator checks how many of the ground truth documents were retrieved.\n",
    "\n",
    "Modes\n",
    "\n",
    "- `RecallMode.SINGLE_HIT`: means that any of the ground truth documents need to be retrieved to count as a correct retrieval with a recall score of 1. A single retrieved document can achieve the full score.\n",
    "\n",
    "- `RecallMode.MULTI_HIT`: means that all of the ground truth documents need to be retrieved to count as a correct retrieval with a recall score of 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usage\n",
    "\n",
    "On its own\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from haystack import Document\n",
    "from haystack.components.evaluators import DocumentRecallEvaluator\n",
    "from haystack.components.evaluators.document_recall import RecallMode\n",
    "\n",
    "\n",
    "evaluator = DocumentRecallEvaluator(mode=RecallMode.SINGLE_HIT)\n",
    "result = evaluator.run(\n",
    "    ground_truth_documents=[\n",
    "        [Document(content=\"France\")], [Document(content=\"9th century\")]\n",
    "    ],\n",
    "    retrieved_documents=[\n",
    "        [Document(content=\"France\")], [Document(content=\"9th century\"), Document(content=\"10th century\")]\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(result['individual_scores'])\n",
    "print(result['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a Pipeline\n",
    "\n",
    "In this example, we use a `DocumentRecallEvaluator` and a `DocumentMRREvaluator` in a pipeline to evaluate two answers and compare them to ground truth answers. Running a pipeline instead of the individual components simplifies calculating more than one metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0]\n",
      "[1.0, 1.0]\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from haystack import Document, Pipeline\n",
    "from haystack.components.evaluators import DocumentMRREvaluator, DocumentRecallEvaluator\n",
    "\n",
    "pipeline = Pipeline()\n",
    "mrr_evaluator = DocumentMRREvaluator()\n",
    "recall_evaluator = DocumentRecallEvaluator()\n",
    "\n",
    "pipeline.add_component(\"mrr_evaluator\", mrr_evaluator)\n",
    "pipeline.add_component(\"recall_evaluator\", recall_evaluator)\n",
    "\n",
    "ground_truth_documents = [\n",
    "    [Document(content=\"France\")], \n",
    "    [Document(content=\"9th century\"), Document(content=\"9th\")],\n",
    "]\n",
    "\n",
    "retrieved_documents = [\n",
    "    [Document(content=\"France\")],\n",
    "    [Document(content=\"9th century\"), Document(content=\"10th century\"), Document(content=\"9th\")]\n",
    "]\n",
    "\n",
    "result = pipeline.run({\n",
    "    \"mrr_evaluator\": {\n",
    "        \"ground_truth_documents\": ground_truth_documents,\n",
    "        \"retrieved_documents\": retrieved_documents,\n",
    "    },\n",
    "    \"recall_evaluator\": {\n",
    "        \"ground_truth_documents\": ground_truth_documents,\n",
    "        \"retrieved_documents\": retrieved_documents\n",
    "    }\n",
    "})\n",
    "\n",
    "for evaluator in result:\n",
    "    print(result[evaluator]['individual_scores'])\n",
    "    \n",
    "for evaluator in result:\n",
    "    print(result[evaluator]['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### DocumentMRREvaluator (Mean Reciprocal Rank)\n",
    "\n",
    "In contrast to the recall metric, mean reciprocal rank takes the position of the top correctly retrieved documents (the \"rank\") into account. \n",
    "\n",
    "It checks at what rank ground truth documents appear in the list of retrieved documents. The metric is called mean reciprocal rank (MRR).\n",
    "\n",
    "A higher mean reciprocal rank is better and indicates that relevant documents appear at an earlier position in the list of retrieved documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usage\n",
    "\n",
    "On its own\n",
    "\n",
    "The example below evaluates documents retrieved for two queries. The first query, there is one ground truth document and one retrieved document.\n",
    "\n",
    "The second query, there are two ground truth documents and three retrieved documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from haystack import Document\n",
    "from haystack.components.evaluators import DocumentMRREvaluator\n",
    "\n",
    "evaluator = DocumentMRREvaluator()\n",
    "result = evaluator.run(\n",
    "    ground_truth_documents=[ \n",
    "                    [Document(content=\"France\")] ,\n",
    "                    [Document(content=\"9th century\"), Document(content=\"9th\")]\n",
    "    ],\n",
    "    retrieved_documents=[ \n",
    "                    [Document(content=\"France\")] ,\n",
    "                    [Document(content=\"9th century\"), Document(content=\"10th\"), Document(content=\"9th\")]\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(result['individual_scores'])\n",
    "print(result['score'])       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a Pipeline\n",
    "\n",
    "Same as the `DocumentRecallEvaluator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrr_evaluator [1.0, 1.0]\n",
      "recall_evaluator [1.0, 1.0]\n",
      "\n",
      "\n",
      "mrr_evaluator 1.0\n",
      "recall_evaluator 1.0\n"
     ]
    }
   ],
   "source": [
    "from haystack import Document, Pipeline\n",
    "from haystack.components.evaluators import DocumentMRREvaluator, DocumentRecallEvaluator\n",
    "\n",
    "pipeline = Pipeline()\n",
    "mrr_evaluator = DocumentMRREvaluator()\n",
    "recall_evaluator = DocumentRecallEvaluator()\n",
    "\n",
    "pipeline.add_component(\"mrr_evaluator\", mrr_evaluator)\n",
    "pipeline.add_component(\"recall_evaluator\", recall_evaluator)\n",
    "\n",
    "ground_truth_documents = [\n",
    "    [Document(content=\"France\")], \n",
    "    [Document(content=\"9th century\"), Document(content=\"9th\")],\n",
    "]\n",
    "\n",
    "retrieved_documents = [\n",
    "    [Document(content=\"France\")],\n",
    "    [Document(content=\"9th century\"), Document(content=\"10th century\"), Document(content=\"9th\")]\n",
    "]\n",
    "\n",
    "result = pipeline.run({\n",
    "    \"mrr_evaluator\": {\n",
    "        \"ground_truth_documents\": ground_truth_documents,\n",
    "        \"retrieved_documents\": retrieved_documents,\n",
    "    },\n",
    "    \"recall_evaluator\": {\n",
    "        \"ground_truth_documents\": ground_truth_documents,\n",
    "        \"retrieved_documents\": retrieved_documents\n",
    "    }\n",
    "})\n",
    "\n",
    "for evaluator in result:\n",
    "    print(evaluator, result[evaluator]['individual_scores'])\n",
    "    \n",
    "print('\\n')\n",
    "for evaluator in result:\n",
    "    print(evaluator, result[evaluator]['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### DocumentMAPEvaluator (Mean Average Precision)\n",
    "\n",
    "This component can be used to evaluate documents, a higher mean average precision is better, indicating that the list of retrieved documents contains many relevant documents and only a few non-relevant documents or none at all. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usage\n",
    "\n",
    "On its own\n",
    "\n",
    "Showing for two queries, the first one has one ground truth and one retrieved document.\n",
    "The other query has 2 ground truths, and 3 retrieved documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.8333333333333333]\n",
      "0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "from haystack import Document\n",
    "from haystack.components.evaluators import DocumentMAPEvaluator\n",
    "\n",
    "evaluator = DocumentMAPEvaluator()\n",
    "result = evaluator.run(\n",
    "    ground_truth_documents=[\n",
    "        [Document(content=\"France\")],\n",
    "        [Document(content=\"9th century\"), Document(content=\"9th\")],\n",
    "    ],\n",
    "    retrieved_documents=[\n",
    "        [Document(content=\"France\")],\n",
    "        [Document(content=\"9th century\"), Document(content=\"10th century\"), Document(content=\"9th\")]\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(result['individual_scores'])\n",
    "print(result['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrr_evaluator [1.0, 1.0]\n",
      "map_evaluator [1.0, 0.8333333333333333]\n",
      "\n",
      "\n",
      "mrr_evaluator 1.0\n",
      "map_evaluator 0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "from haystack import Document, Pipeline\n",
    "from haystack.components.evaluators import DocumentMRREvaluator, DocumentMAPEvaluator\n",
    "\n",
    "pipeline = Pipeline()\n",
    "mrr_evaluator = DocumentMRREvaluator()\n",
    "map_evaluator = DocumentMAPEvaluator()\n",
    "pipeline.add_component(\"mrr_evaluator\", mrr_evaluator)\n",
    "pipeline.add_component(\"map_evaluator\", map_evaluator)\n",
    "\n",
    "ground_truth_documents = [\n",
    "    [Document(content=\"France\")],\n",
    "    [Document(content=\"9th century\"), Document(content=\"9th\")]\n",
    "]\n",
    "retrieved_documents = [\n",
    "    [Document(content=\"France\")],\n",
    "    [Document(content=\"9th century\"), Document(content=\"10th century\"), Document(content=\"9th\")]\n",
    "]\n",
    "\n",
    "result = pipeline.run({\n",
    "    \"mrr_evaluator\": {\n",
    "        \"ground_truth_documents\": ground_truth_documents,\n",
    "        \"retrieved_documents\": retrieved_documents,\n",
    "    },\n",
    "    \"map_evaluator\": {\n",
    "        \"ground_truth_documents\": ground_truth_documents,\n",
    "        \"retrieved_documents\": retrieved_documents,\n",
    "    }\n",
    "})\n",
    "\n",
    "for evaluator in result:\n",
    "    print(evaluator, result[evaluator]['individual_scores'])\n",
    "print('\\n')\n",
    "for evaluator in result:\n",
    "    print(evaluator, result[evaluator]['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical Evalution of Extracted or Generated Answers\n",
    "\n",
    "##### AnswerExactMatchEvaluator\n",
    "\n",
    "This component checks character by character whether a predicted answer exactly matches the ground truth answer. This metric is called exact match.\n",
    "\n",
    "This is useful for evaluating an extractive question answering pipeline against ground truth labels. \n",
    "\n",
    "`AnswerExactMatchEvaluator` checks whether a predicted answer exactly matches the ground truth answer. It is not suited to evaluate answers generated by LLMs. use `FaithfulnessEvaluator` or `SASEvaluator` instead.\n",
    "\n",
    "One predicted answer is compared to one ground truth answer at a time.\n",
    "\n",
    "If matches are not same, the value will be 0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usage\n",
    "\n",
    "On its own\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0]\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "from haystack.components.evaluators import AnswerExactMatchEvaluator\n",
    "\n",
    "evaluator = AnswerExactMatchEvaluator()\n",
    "result = evaluator.run(\n",
    "    ground_truth_answers=[\"Berlin\", \"Paris\"],\n",
    "    predicted_answers=[\"Berlin\", \"Lyon\"]\n",
    ")\n",
    "\n",
    "print(result['individual_scores'])\n",
    "print(result['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "em_evaluator [1, 0]\n",
      "sas_evaluator [0.9999999403953552, 0.5174765586853027]\n",
      "\n",
      "\n",
      "em_evaluator 0.5\n",
      "sas_evaluator 0.758738249540329\n"
     ]
    }
   ],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.components.evaluators import AnswerExactMatchEvaluator\n",
    "\n",
    "# SASEvaluator uses a cross-encoder model\n",
    "from haystack.components.evaluators import SASEvaluator\n",
    "\n",
    "pipeline = Pipeline()\n",
    "em_evaluator = AnswerExactMatchEvaluator()\n",
    "sas_evaluator = SASEvaluator()\n",
    "pipeline.add_component(\"em_evaluator\", em_evaluator)\n",
    "pipeline.add_component(\"sas_evaluator\", sas_evaluator)\n",
    "\n",
    "ground_truth_answers = [\"Berlin\", \"Paris\"]\n",
    "predicted_answers = [\"Berlin\", \"Lyon\"]\n",
    "\n",
    "result = pipeline.run({\n",
    "    \"em_evaluator\": {\n",
    "        \"ground_truth_answers\": ground_truth_answers,\n",
    "        \"predicted_answers\": predicted_answers\n",
    "    },\n",
    "    \"sas_evaluator\": {\n",
    "        \"ground_truth_answers\": ground_truth_answers,\n",
    "        \"predicted_answers\": predicted_answers,\n",
    "    },\n",
    "})\n",
    "\n",
    "for evaluator in result:\n",
    "    print(evaluator, result[evaluator]['individual_scores'])\n",
    "print('\\n')\n",
    "for evaluator in result:\n",
    "    print(evaluator, result[evaluator]['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B: Practical Examples\n",
    "\n",
    "We would evaluate RAG pipelines both with model-based and statistical metrics available in Haystack evaluation offering.\n",
    "\n",
    "1. Build a pipeline that answers medical questions based on PubMed data\n",
    "2. Build an evaluation pipeline that makes use of some metrics like Document MRR and Answer Faithfulness\n",
    "3. Run the RAG pipeline and evaluate the output with our evaluation pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 498/498 [00:00<00:00, 1.14MB/s]\n",
      "Downloading data: 100%|██████████| 274M/274M [00:09<00:00, 29.7MB/s] \n",
      "Downloading data: 100%|██████████| 986k/986k [00:00<00:00, 2.74MB/s]\n",
      "Generating train split: 100%|██████████| 272458/272458 [00:02<00:00, 124627.70 examples/s]\n",
      "Generating test split: 100%|██████████| 1000/1000 [00:00<00:00, 105284.00 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from haystack import Document\n",
    "\n",
    "dataset = load_dataset(\"vblagoje/PubMedQA_instruction\", split=\"train\")\n",
    "dataset = dataset.select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_documents = [Document(content=doc[\"context\"]) for doc in dataset]\n",
    "all_questions = [doc['instruction'] for doc in dataset]\n",
    "all_ground_truth_answers = [doc['response'] for doc in dataset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build an Indexing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/solomon/Documents/projects/AI/learning_haystack/env/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:173: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v3 of SentenceTransformers.\n",
      "  warnings.warn(\n",
      "/home/solomon/Documents/projects/AI/learning_haystack/env/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Batches: 100%|██████████| 32/32 [00:01<00:00, 16.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'document_writer': {'documents_written': 1000}}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "from haystack import Pipeline\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.document_stores.types import DuplicatePolicy\n",
    "\n",
    "document_store = InMemoryDocumentStore()\n",
    "\n",
    "document_embedder = SentenceTransformersDocumentEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "document_writer = DocumentWriter(document_store=document_store, policy=DuplicatePolicy.SKIP)\n",
    "\n",
    "indexing = Pipeline()\n",
    "indexing.add_component(instance=document_embedder, name=\"document_embedder\")\n",
    "indexing.add_component(instance=document_writer, name=\"document_writer\")\n",
    "\n",
    "indexing.connect(\"document_embedder.documents\", \"document_writer.documents\")\n",
    "indexing.run({\n",
    "    \"document_embedder\": {\n",
    "        \"documents\": all_documents\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x752c1406c7d0>\n",
       "🚅 Components\n",
       "  - query_embedder: SentenceTransformersTextEmbedder\n",
       "  - retriever: InMemoryEmbeddingRetriever\n",
       "  - prompt_builder: PromptBuilder\n",
       "  - generator: OpenAIGenerator\n",
       "  - answer_builder: AnswerBuilder\n",
       "🛤️ Connections\n",
       "  - query_embedder.embedding -> retriever.query_embedding (List[float])\n",
       "  - retriever.documents -> prompt_builder.documents (List[Document])\n",
       "  - retriever.documents -> answer_builder.documents (List[Document])\n",
       "  - prompt_builder.prompt -> generator.prompt (str)\n",
       "  - generator.replies -> answer_builder.replies (List[str])\n",
       "  - generator.meta -> answer_builder.meta (List[Dict[str, Any]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from haystack.components.builders import AnswerBuilder, PromptBuilder\n",
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
    "\n",
    "if os.getenv(\"OPENAI_API_KEY\") is None:\n",
    "    raise ValueError(\"OPENAI_API_KEY is required\")\n",
    "\n",
    "template = \"\"\"\n",
    "You have to answer the following question based on the given context information only.\n",
    "\n",
    "Context:\n",
    "\n",
    "{% for document in documents %}\n",
    "    {{ document.content }}\n",
    "{% endfor %}\n",
    "\n",
    "Question: {{question}}\n",
    "Answer:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "rag_pipeline = Pipeline()\n",
    "rag_pipeline.add_component(\"query_embedder\", SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\"))\n",
    "rag_pipeline.add_component(\"retriever\", InMemoryEmbeddingRetriever(document_store=document_store))\n",
    "rag_pipeline.add_component(\"prompt_builder\", PromptBuilder(template=template) )\n",
    "rag_pipeline.add_component(\"generator\", OpenAIGenerator(model=\"gpt-3.5-turbo\"))\n",
    "rag_pipeline.add_component(\"answer_builder\", AnswerBuilder())\n",
    "\n",
    "rag_pipeline.connect(\"query_embedder\", \"retriever.query_embedding\")\n",
    "rag_pipeline.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "rag_pipeline.connect(\"prompt_builder\", \"generator\")\n",
    "rag_pipeline.connect(\"generator.replies\", \"answer_builder.replies\")\n",
    "rag_pipeline.connect(\"generator.meta\", \"answer_builder.meta\")\n",
    "rag_pipeline.connect(\"retriever\", \"answer_builder.documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Asking a Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, high levels of procalcitonin in the early phase after pediatric liver transplantation indicate poor postoperative outcome. Patients with high PCT levels on postoperative day 2 had higher International Normalized Ratio values on postoperative day 5, suffered more from primary graft non-function, had a longer stay in the pediatric intensive care unit and on mechanical ventilation.\n"
     ]
    }
   ],
   "source": [
    "question = \"Do high levels of procalcitoni in the early phase after pediatric liver transplantation indicate poor postoperative outcome? \"\n",
    "\n",
    "response = rag_pipeline.run({\n",
    "    \"query_embedder\": {\n",
    "        \"text\": question\n",
    "    },\n",
    "    \"prompt_builder\": {\n",
    "        \"question\": question\n",
    "    },\n",
    "    \"answer_builder\": {\n",
    "        \"query\": question\n",
    "    }\n",
    "})\n",
    "\n",
    "\n",
    "print(response[\"answer_builder\"][\"answers\"][0].data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the Pipeline\n",
    "\n",
    "We will use the following metrics to evaluate the pipeline\n",
    "1. Document Mean Reciprocal Rank\n",
    "2. Semantic Answer Similarity\n",
    "3. Faithfulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "questions, ground_truth_answers, ground_truth_docs = zip(*random.sample(list(zip(all_questions, all_ground_truth_answers, all_documents)), 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 33.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Does biolimus-eluting stent with biodegradable polymer improve clinical outcomes in patients with acute myocardial infarction?\n",
      "Answer from pipeline: \n",
      "Yes, the biolimus-eluting stent (BES) with biodegradable polymer significantly reduces patient-oriented composite endpoint (POCE) and major adverse cardiac events (MACE) compared to the sirolimus-eluting stent (SES) in patients with acute myocardial infarction (AMI) at the 5-year follow-up.\n",
      "\n",
      "-----------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 50.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Does chloroquine enhance temozolomide cytotoxicity in malignant gliomas by blocking autophagy?\n",
      "Answer from pipeline: \n",
      "Yes, chloroquine enhances temozolomide cytotoxicity in malignant gliomas by blocking autophagy.\n",
      "\n",
      "-----------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is head-shaft angle a risk factor for hip displacement in children with cerebral palsy?\n",
      "Answer from pipeline: \n",
      "Yes, based on the context information provided, the head-shaft angle (HSA) is indeed identified as a risk factor for hip displacement in children with cerebral palsy. The study found that a 10-degree difference in HSA resulted in a 1.6-times higher risk of hip displacement in children with a higher HSA, even when age, migration percentage (MP), and Gross Motor Function Classification System (GMFCS) level were taken into account.\n",
      "\n",
      "-----------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is high-flow-mediated constriction in adults influenced by biomarkers of cardiovascular and metabolic risk?\n",
      "Answer from pipeline: \n",
      "Yes, high-flow-mediated constriction (H-FMC) in adults is influenced by biomarkers of cardiovascular and metabolic risk. In the study mentioned in the context, H-FMC was observed in approximately 69% of adult participants, and it was found to be related to body composition and biomarkers of cardiovascular and metabolic risk such as total body mass, fat mass, body mass index, glucose, insulin, and lipids. Participants with certain cardiovascular risk factors showed significantly higher epicardial adipose tissue (EAT) thickness and carotid intima media thickness (CIMT), which are biomarkers associated with cardiovascular risk. These findings suggest that biomarkers of cardiovascular and metabolic risk can influence high-flow-mediated constriction in adults.\n",
      "\n",
      "-----------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 51.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is fibromyalgia associated with coronary heart disease : a population-based cohort study?\n",
      "Answer from pipeline: \n",
      "Yes, based on the information provided in the context, fibromyalgia is associated with an increased risk of coronary heart disease (CHD). The study used a matched-cohort design and analyzed data from the Longitudinal Health Insurance Database 2000 in Taiwan. It was found that patients with fibromyalgia had a significantly higher subsequent risk of a CHD event compared to patients without fibromyalgia (hazard ratio, 2.11; 95% confidence interval, 1.46-3.05; P < 0.001).\n",
      "\n",
      "-----------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Do increased litter size and suckling intensity inhibit KiSS-1 mRNA expression in rat arcuate nucleus?\n",
      "Answer from pipeline: \n",
      "Yes, increased litter size and suckling intensity inhibit KiSS-1 mRNA expression in the rat arcuate nucleus. The expression of KiSS-1 mRNA in the arcuate nucleus was decreased as the litter size and intensity of the suckling stimulus were increased. The effect of suckling intensity on the expression of KiSS-1 mRNA was more pronounced than that of litter size.\n",
      "\n",
      "-----------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is tPH1 A218 allele associated with suicidal behavior in Turkish population?\n",
      "Answer from pipeline: \n",
      "Yes, the tPH1 A218 allele is associated with suicidal behavior in the Turkish population, as the frequency of the A allele was significantly higher in suicide attempters compared to healthy controls in the study mentioned in the context information. The study found that the A allele frequency was 46.33% in suicide attempters, compared to 35.71% in healthy controls (p=0.0357).\n",
      "\n",
      "-----------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 51.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Are hair Cortisol Concentrations in Adolescent Girls with Anorexia Nervosa Lower Compared to Healthy and Psychiatric Controls?\n",
      "Answer from pipeline: \n",
      "Yes, according to the provided context information, hair Cortisol Concentrations in Adolescent Girls with Anorexia Nervosa are lower compared to Healthy controls(p=0.030) and Psychiatric controls. This was determined through an analysis of hair cortisol concentration as a marker for long-term integrated cortisol secretion in female patients with AN compared to female healthy controls (HC) and female psychiatric controls (PC).\n",
      "\n",
      "-----------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is shorter time to target temperature associated with poor neurologic outcome in post-arrest patients treated with targeted temperature management?\n",
      "Answer from pipeline: \n",
      "Yes, shorter time from initiation of cooling to target temperature (\"induction\") was associated with worse neurologic outcome in post-arrest patients treated with targeted temperature management. The study found that induction time >300 minutes was associated with good neurologic outcome compared to those with induction time <120 minutes.\n",
      "\n",
      "-----------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Do plasma levels of Galectin-9 reflect disease severity in malaria infection?\n",
      "Answer from pipeline: \n",
      "Yes, plasma levels of Galectin-9 (Gal-9) reflect disease severity in malaria infection. The study found that Gal-9 levels were higher in severe malaria cases compared to uncomplicated cases at day 0 and day 7. This suggests that higher levels of Gal-9 in plasma are associated with more severe forms of malaria infection.\n",
      "\n",
      "-----------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is plasma MicroRNA-126-5p Associated with the Complexity and Severity of Coronary Artery Disease in Patients with Stable Angina Pectoris?\n",
      "Answer from pipeline: \n",
      "Yes, plasma MicroRNA-126-5p levels were found to be significantly down-regulated in patients with stable angina pectoris who had multi-vessel disease and higher SYNTAX scores, indicating an association with the complexity and severity of coronary artery disease in these patients.\n",
      "\n",
      "-----------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Do trends in outpatient MRI seem to reflect recent reimbursement cuts?\n",
      "Answer from pipeline: \n",
      "Yes, trends in outpatient MRI show that office volume steadily declined while hospital outpatient department (HOPD) volume steadily increased, indicating a shift of outpatient MRI from private offices to HOPDs. This shift could potentially be a response to recent reimbursement cuts.\n",
      "\n",
      "-----------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is postural change during venous blood collection a major source of bias in clinical chemistry testing?\n",
      "Answer from pipeline: \n",
      "Yes, postural change during venous blood collection is a major source of bias in clinical chemistry testing. The study mentioned in the context found that parameters such as hemoglobin, hematocrit, albumin, alkaline phosphatase, and others exhibited meaningful increases when participants changed from a supine position to a sitting or standing position. This indicates that the posture during blood collection can significantly affect the results of clinical chemistry testing.\n",
      "\n",
      "-----------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 54.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Are plant communities on infertile soils less sensitive to climate change?\n",
      "Answer from pipeline: \n",
      "Based on the multi-decadal study conducted in the western USA, it was found that plant communities on infertile soils (serpentine) were not less sensitive to climate change. The study showed that overstorey cover, rather than soil fertility, was a significant covariate of community change over time. Additionally, the community mean specific leaf area showed less change over time in serpentine communities, indicating that they were not less sensitive to climate change. Therefore, plant communities on infertile soils do not appear to be less sensitive to climate change based on the evidence provided.\n",
      "\n",
      "-----------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 57.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Does direct transfer of HRPII-magnetic bead complexes to malaria rapid diagnostic tests significantly improve test sensitivity?\n",
      "Answer from pipeline: \n",
      "Yes, the direct transfer of HRPII-magnetic bead complexes to malaria rapid diagnostic tests significantly improves test sensitivity. The limit of detection of the Paracheck Pf RDT brand was improved by 21-fold, resulting in a limit of detection below 1 parasite/µL using this method.\n",
      "\n",
      "-----------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 54.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Do evolution of clinical features in possible DLB depending on FP-CIT SPECT result?\n",
      "Answer from pipeline: \n",
      "Yes, the evolution of clinical features in patients with possible DLB did vary depending on the (123)I-FP-CIT SPECT scan result. Patients with abnormal imaging had a significant increase in Unified Parkinson's Disease Rating Scale (UPDRS) score over time compared to those with normal imaging. There was relatively little evolution of the rest of the DLB features regardless of the imaging result.\n",
      "\n",
      "-----------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 132.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Are statin medications associated with a lower probability of having an abnormal screening prostate-specific antigen result?\n",
      "Answer from pipeline: \n",
      "Yes, statin medications are associated with a lower probability of having an abnormal screening prostate-specific antigen result. The percentages of men with PSA results exceeding commonly used thresholds of >2.5, >4.0, and >6.5 ng/mL were lower in men using statin medications, and the adjusted relative risks of having a PSA level >4.0 ng/mL were lower in men prescribed with higher doses of statins compared to non-statin users.\n",
      "\n",
      "-----------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 251.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is negative feedback loop of cholesterol regulation impaired in the livers of patients with Alagille syndrome?\n",
      "Answer from pipeline: \n",
      "No, the negative feedback loop of cholesterol regulation is not impaired in the livers of patients with Alagille syndrome. The expression of mature SREBP2 protein was not suppressed in these patients, indicating that the regulation of cholesterol synthesis and uptake is functioning as normal.\n",
      "\n",
      "-----------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Does obesity increase risk of anticoagulation reversal failure with prothrombin complex concentrate in those with intracranial hemorrhage?\n",
      "Answer from pipeline: \n",
      "Yes, obesity was identified as a factor associated with anticoagulation reversal failure after the first dose of prothrombin complex concentrate in patients with warfarin-related acute intracranial hemorrhage. Patients who were obese (body mass index > 30 kg/m(2)) had a higher likelihood of anticoagulation reversal failure compared to those who were not obese.\n",
      "\n",
      "-----------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 281.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Does implementation of the acute care surgery model provide benefits in the surgical treatment of the acute appendicitis?\n",
      "Answer from pipeline: \n",
      "Yes, implementation of the acute care surgery (ACS) model provides benefits in the surgical treatment of acute appendicitis. The study found that the overall emergency department (ED) length of stay was significantly shorter in the ACS model compared to the pre-ACS model. Additionally, hospital length of stay (LOS) was also significantly shorter in the ACS model. Therefore, the ACS model improves surgical efficiency and quality outcomes in the treatment of acute appendicitis.\n",
      "\n",
      "-----------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 66.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Do [ Perinatal variables from newborns of Aymara mothers suggest a genetic adaptation to high altitude ]?\n",
      "Answer from pipeline: \n",
      "Yes, perinatal variables from newborns of Aymara mothers suggest a genetic adaptation to high altitude, as women with Aymara ancestry gave birth to children with higher gestational age, weight, and cranial circumference, indicating some level of adaptation to living at high altitudes.\n",
      "\n",
      "-----------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 51.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Does prospective international cohort study demonstrate inability of interim PET to predict treatment failure in diffuse large B-cell lymphoma?\n",
      "Answer from pipeline: \n",
      "No, the prospective international cohort study demonstrates that interim PET (I-PET) is able to predict treatment failure in diffuse large B-cell lymphoma. The study found that a positive I-PET result was associated with significantly lower event-free survival and overall survival rates compared to a negative I-PET result.\n",
      "\n",
      "-----------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Does macrolide Resistance in Treponema pallidum correlate With 23S rDNA Mutations in Recently Isolated Clinical Strains?\n",
      "Answer from pipeline: \n",
      "Yes, the high rates of 23S rDNA mutations in Treponema pallidum isolated from syphilis patients do correlate with macrolide resistance, as demonstrated by the failure of azithromycin to cure rabbits infected with strains containing these mutations in a recent study.\n",
      "\n",
      "-----------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 54.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Does early tracheostomy in trauma patients save time and money?\n",
      "Answer from pipeline: \n",
      "Yes, early tracheostomy in trauma patients does save time and money. Patients in the early tracheostomy group had significantly shorter TICU (Trauma Intensive Care Unit) LOS (Length of Stay) and significantly fewer ventilator days compared to the late tracheostomy group. Additionally, early tracheostomy patients had significantly less Ventilator-Associated Pneumonia (VAP). The study also mentioned that cost for services was calculated using average daily billing rates at the institution, indicating potential cost savings with early tracheostomy.\n",
      "\n",
      "-----------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 51.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is self-reported physical activity in smoking pre-cessation a protective factor against relapse for all?\n",
      "Answer from pipeline: \n",
      "Based on the context provided, the study evaluated the impact of self-reported physical activity (PA) in precessation on smoking relapse. After adjusting for potential confounders, it was found that PA was not associated with smoking relapse. Therefore, self-reported physical activity in smoking pre-cessation is not a protective factor against relapse for all. Other factors such as self-efficacy level, absence of professional activity, previous attempts to quit, and alcohol use disorders were associated with smoking relapse.\n",
      "\n",
      "-----------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rag_answers = []\n",
    "retrieved_docs = []\n",
    "\n",
    "for question in list(questions):\n",
    "    response = rag_pipeline.run({\n",
    "        \"query_embedder\": {\n",
    "            \"text\": question\n",
    "        },\n",
    "        \"prompt_builder\": {\n",
    "            \"question\": question\n",
    "        },\n",
    "        \"answer_builder\": {\n",
    "            \"query\": question\n",
    "            }\n",
    "            }\n",
    "        )\n",
    "    print(f\"Question: {question}\")\n",
    "    print(\"Answer from pipeline: \")\n",
    "    print(response[\"answer_builder\"][\"answers\"][0].data)\n",
    "    print(\"\\n-----------------------------------\\n\")\n",
    "    \n",
    "    rag_answers.append(response[\"answer_builder\"][\"answers\"][0].data)\n",
    "    retrieved_docs.append(response[\"answer_builder\"][\"answers\"][0].documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perform the Evaluation\n",
    "We then perform the three evaluations on the 25 questions and answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:40<00:00,  1.64s/it]\n"
     ]
    }
   ],
   "source": [
    "from haystack.components.evaluators.document_mrr import DocumentMRREvaluator\n",
    "from haystack.components.evaluators.faithfulness import FaithfulnessEvaluator\n",
    "from haystack.components.evaluators.sas_evaluator import SASEvaluator\n",
    "\n",
    "eval_pipeline = Pipeline()\n",
    "eval_pipeline.add_component(\"doc_mrr_evaluator\", DocumentMRREvaluator())\n",
    "eval_pipeline.add_component(\"faithfulness\", FaithfulnessEvaluator())\n",
    "eval_pipeline.add_component(\"sas_evaluator\", SASEvaluator())\n",
    "\n",
    "results = eval_pipeline.run({\n",
    "    \"doc_mrr_evaluator\": {\n",
    "        \"ground_truth_documents\": list([d] for d in ground_truth_docs),\n",
    "        \"retrieved_documents\": retrieved_docs\n",
    "    },\n",
    "    \"faithfulness\": {\n",
    "        \"questions\": list(questions), \n",
    "        \"contexts\": list([d] for d in ground_truth_docs), \n",
    "        \"predicted_answers\": rag_answers\n",
    "        },\n",
    "    \"sas_evaluator\": {\n",
    "        \"predicted_answers\": rag_answers, \"ground_truth_answers\": list(ground_truth_answers)\n",
    "    },\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Constructing an Evaluation Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doc_mrr_evaluator</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faithfulness</th>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sas_evaluator</th>\n",
       "      <td>0.760169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      score\n",
       "doc_mrr_evaluator  1.000000\n",
       "faithfulness       0.960000\n",
       "sas_evaluator      0.760169"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack.evaluation.eval_run_result import EvaluationRunResult\n",
    "\n",
    "inputs = {\n",
    "    \"question\": list(questions),\n",
    "    \"context\": list([d.content] for d in ground_truth_docs),\n",
    "    \"answer\": list(ground_truth_answers),\n",
    "    \"predicted_answer\": rag_answers\n",
    "}\n",
    "\n",
    "evaluation_result= EvaluationRunResult(run_name=\"pubmed_rag_pipeline\", inputs=inputs, results=results)\n",
    "evaluation_result.score_report()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert the Report into a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>predicted_answer</th>\n",
       "      <th>doc_mrr_evaluator</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>sas_evaluator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Does biolimus-eluting stent with biodegradable...</td>\n",
       "      <td>[To investigate clinical outcomes of coronary ...</td>\n",
       "      <td>BES, compared with SES, significantly improved...</td>\n",
       "      <td>Yes, the biolimus-eluting stent (BES) with bio...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.654321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Does chloroquine enhance temozolomide cytotoxi...</td>\n",
       "      <td>[In a recent clinical trial, patients with new...</td>\n",
       "      <td>Taken together, these results demonstrate that...</td>\n",
       "      <td>Yes, chloroquine enhances temozolomide cytotox...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.705631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is head-shaft angle a risk factor for hip disp...</td>\n",
       "      <td>[Hip dislocation in children with cerebral pal...</td>\n",
       "      <td>A high HSA appears to be a risk factor for hip...</td>\n",
       "      <td>Yes, based on the context information provided...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.835098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is high-flow-mediated constriction in adults i...</td>\n",
       "      <td>[During reactive hyperemia, the brachial arter...</td>\n",
       "      <td>Increased body mass, fat mass, and body mass i...</td>\n",
       "      <td>Yes, high-flow-mediated constriction (H-FMC) i...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is fibromyalgia associated with coronary heart...</td>\n",
       "      <td>[We examined whether patients with a diagnosis...</td>\n",
       "      <td>An association between fibromyalgia and CHD ap...</td>\n",
       "      <td>Yes, based on the information provided in the ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.747827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Do increased litter size and suckling intensit...</td>\n",
       "      <td>[The effect of litter size and suckling intens...</td>\n",
       "      <td>Increased litter size and suckling intensity d...</td>\n",
       "      <td>Yes, increased litter size and suckling intens...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.801956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Is tPH1 A218 allele associated with suicidal b...</td>\n",
       "      <td>[Serotonergic dysfunction is implicated in dep...</td>\n",
       "      <td>Our results provide evidence that A allele of ...</td>\n",
       "      <td>Yes, the tPH1 A218 allele is associated with s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.920216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Are hair Cortisol Concentrations in Adolescent...</td>\n",
       "      <td>[In anorexia nervosa (AN) hypercortisolism has...</td>\n",
       "      <td>We find lower HCC in AN, compared to HC and PC...</td>\n",
       "      <td>Yes, according to the provided context informa...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.610489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Is shorter time to target temperature associat...</td>\n",
       "      <td>[Time to achieve target temperature varies sub...</td>\n",
       "      <td>In this multicenter cohort of post-arrest TTM ...</td>\n",
       "      <td>Yes, shorter time from initiation of cooling t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.712108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Do plasma levels of Galectin-9 reflect disease...</td>\n",
       "      <td>[Galectin-9 (Gal-9) is a β-galactoside-binding...</td>\n",
       "      <td>Gal-9 is released during acute malaria, and re...</td>\n",
       "      <td>Yes, plasma levels of Galectin-9 (Gal-9) refle...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.790772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Is plasma MicroRNA-126-5p Associated with the ...</td>\n",
       "      <td>[Coronary artery disease (CAD) is a major prob...</td>\n",
       "      <td>Circulating miR-126-5p has emerged as a potent...</td>\n",
       "      <td>Yes, plasma MicroRNA-126-5p levels were found ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.734182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Do trends in outpatient MRI seem to reflect re...</td>\n",
       "      <td>[To determine whether recent reimbursement cut...</td>\n",
       "      <td>Although the majority of Medicare outpatient M...</td>\n",
       "      <td>Yes, trends in outpatient MRI show that office...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.809217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Is postural change during venous blood collect...</td>\n",
       "      <td>[To investigate the influence of different phl...</td>\n",
       "      <td>These results provide further support to the n...</td>\n",
       "      <td>Yes, postural change during venous blood colle...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.540411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Are plant communities on infertile soils less ...</td>\n",
       "      <td>[Much evidence suggests that plant communities...</td>\n",
       "      <td>Based on the current balance of evidence, plan...</td>\n",
       "      <td>Based on the multi-decadal study conducted in ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.845297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Does direct transfer of HRPII-magnetic bead co...</td>\n",
       "      <td>[The characteristic ease of use, rapid time to...</td>\n",
       "      <td>This approach has the sensitivity and simplici...</td>\n",
       "      <td>Yes, the direct transfer of HRPII-magnetic bea...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.663572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Do evolution of clinical features in possible ...</td>\n",
       "      <td>[To test the hypothesis that core and suggesti...</td>\n",
       "      <td>In patients with possible DLB, apart from UPDR...</td>\n",
       "      <td>Yes, the evolution of clinical features in pat...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.819001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Are statin medications associated with a lower...</td>\n",
       "      <td>[To investigate how statin use is associated w...</td>\n",
       "      <td>Statin use is associated with a reduction in t...</td>\n",
       "      <td>Yes, statin medications are associated with a ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.816584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Is negative feedback loop of cholesterol regul...</td>\n",
       "      <td>[To characterize cholesterol regulation in the...</td>\n",
       "      <td>The major upregulators of liver cholesterol mi...</td>\n",
       "      <td>No, the negative feedback loop of cholesterol ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.677808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Does obesity increase risk of anticoagulation ...</td>\n",
       "      <td>[Not all patients with warfarin-related acute ...</td>\n",
       "      <td>Obesity and elevated initial INR are independe...</td>\n",
       "      <td>Yes, obesity was identified as a factor associ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.730862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Does implementation of the acute care surgery ...</td>\n",
       "      <td>[Several reports have indicated the benefits o...</td>\n",
       "      <td>The ACS model may improve abdominal surgical e...</td>\n",
       "      <td>Yes, implementation of the acute care surgery ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.795096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Do [ Perinatal variables from newborns of Ayma...</td>\n",
       "      <td>[Studies performed in Andean populations livin...</td>\n",
       "      <td>Altitude of residence is related to a decrease...</td>\n",
       "      <td>Yes, perinatal variables from newborns of Ayma...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.785332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Does prospective international cohort study de...</td>\n",
       "      <td>[The International Atomic Energy Agency sponso...</td>\n",
       "      <td>This large international cohort delivers 3 nov...</td>\n",
       "      <td>No, the prospective international cohort study...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.800335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Does macrolide Resistance in Treponema pallidu...</td>\n",
       "      <td>[High rates of 23S rDNA mutations implicated i...</td>\n",
       "      <td>A macrolide resistant phenotype was demonstrat...</td>\n",
       "      <td>Yes, the high rates of 23S rDNA mutations in T...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.677838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Does early tracheostomy in trauma patients sav...</td>\n",
       "      <td>[Patients suffering traumatic brain and chest ...</td>\n",
       "      <td>In the current era of increased health-care co...</td>\n",
       "      <td>Yes, early tracheostomy in trauma patients doe...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.858520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Is self-reported physical activity in smoking ...</td>\n",
       "      <td>[In recent years, the relationship between phy...</td>\n",
       "      <td>Previous quit attempts and professional activi...</td>\n",
       "      <td>Based on the context provided, the study evalu...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.838644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0   Does biolimus-eluting stent with biodegradable...   \n",
       "1   Does chloroquine enhance temozolomide cytotoxi...   \n",
       "2   Is head-shaft angle a risk factor for hip disp...   \n",
       "3   Is high-flow-mediated constriction in adults i...   \n",
       "4   Is fibromyalgia associated with coronary heart...   \n",
       "5   Do increased litter size and suckling intensit...   \n",
       "6   Is tPH1 A218 allele associated with suicidal b...   \n",
       "7   Are hair Cortisol Concentrations in Adolescent...   \n",
       "8   Is shorter time to target temperature associat...   \n",
       "9   Do plasma levels of Galectin-9 reflect disease...   \n",
       "10  Is plasma MicroRNA-126-5p Associated with the ...   \n",
       "11  Do trends in outpatient MRI seem to reflect re...   \n",
       "12  Is postural change during venous blood collect...   \n",
       "13  Are plant communities on infertile soils less ...   \n",
       "14  Does direct transfer of HRPII-magnetic bead co...   \n",
       "15  Do evolution of clinical features in possible ...   \n",
       "16  Are statin medications associated with a lower...   \n",
       "17  Is negative feedback loop of cholesterol regul...   \n",
       "18  Does obesity increase risk of anticoagulation ...   \n",
       "19  Does implementation of the acute care surgery ...   \n",
       "20  Do [ Perinatal variables from newborns of Ayma...   \n",
       "21  Does prospective international cohort study de...   \n",
       "22  Does macrolide Resistance in Treponema pallidu...   \n",
       "23  Does early tracheostomy in trauma patients sav...   \n",
       "24  Is self-reported physical activity in smoking ...   \n",
       "\n",
       "                                              context  \\\n",
       "0   [To investigate clinical outcomes of coronary ...   \n",
       "1   [In a recent clinical trial, patients with new...   \n",
       "2   [Hip dislocation in children with cerebral pal...   \n",
       "3   [During reactive hyperemia, the brachial arter...   \n",
       "4   [We examined whether patients with a diagnosis...   \n",
       "5   [The effect of litter size and suckling intens...   \n",
       "6   [Serotonergic dysfunction is implicated in dep...   \n",
       "7   [In anorexia nervosa (AN) hypercortisolism has...   \n",
       "8   [Time to achieve target temperature varies sub...   \n",
       "9   [Galectin-9 (Gal-9) is a β-galactoside-binding...   \n",
       "10  [Coronary artery disease (CAD) is a major prob...   \n",
       "11  [To determine whether recent reimbursement cut...   \n",
       "12  [To investigate the influence of different phl...   \n",
       "13  [Much evidence suggests that plant communities...   \n",
       "14  [The characteristic ease of use, rapid time to...   \n",
       "15  [To test the hypothesis that core and suggesti...   \n",
       "16  [To investigate how statin use is associated w...   \n",
       "17  [To characterize cholesterol regulation in the...   \n",
       "18  [Not all patients with warfarin-related acute ...   \n",
       "19  [Several reports have indicated the benefits o...   \n",
       "20  [Studies performed in Andean populations livin...   \n",
       "21  [The International Atomic Energy Agency sponso...   \n",
       "22  [High rates of 23S rDNA mutations implicated i...   \n",
       "23  [Patients suffering traumatic brain and chest ...   \n",
       "24  [In recent years, the relationship between phy...   \n",
       "\n",
       "                                               answer  \\\n",
       "0   BES, compared with SES, significantly improved...   \n",
       "1   Taken together, these results demonstrate that...   \n",
       "2   A high HSA appears to be a risk factor for hip...   \n",
       "3   Increased body mass, fat mass, and body mass i...   \n",
       "4   An association between fibromyalgia and CHD ap...   \n",
       "5   Increased litter size and suckling intensity d...   \n",
       "6   Our results provide evidence that A allele of ...   \n",
       "7   We find lower HCC in AN, compared to HC and PC...   \n",
       "8   In this multicenter cohort of post-arrest TTM ...   \n",
       "9   Gal-9 is released during acute malaria, and re...   \n",
       "10  Circulating miR-126-5p has emerged as a potent...   \n",
       "11  Although the majority of Medicare outpatient M...   \n",
       "12  These results provide further support to the n...   \n",
       "13  Based on the current balance of evidence, plan...   \n",
       "14  This approach has the sensitivity and simplici...   \n",
       "15  In patients with possible DLB, apart from UPDR...   \n",
       "16  Statin use is associated with a reduction in t...   \n",
       "17  The major upregulators of liver cholesterol mi...   \n",
       "18  Obesity and elevated initial INR are independe...   \n",
       "19  The ACS model may improve abdominal surgical e...   \n",
       "20  Altitude of residence is related to a decrease...   \n",
       "21  This large international cohort delivers 3 nov...   \n",
       "22  A macrolide resistant phenotype was demonstrat...   \n",
       "23  In the current era of increased health-care co...   \n",
       "24  Previous quit attempts and professional activi...   \n",
       "\n",
       "                                     predicted_answer  doc_mrr_evaluator  \\\n",
       "0   Yes, the biolimus-eluting stent (BES) with bio...                1.0   \n",
       "1   Yes, chloroquine enhances temozolomide cytotox...                1.0   \n",
       "2   Yes, based on the context information provided...                1.0   \n",
       "3   Yes, high-flow-mediated constriction (H-FMC) i...                1.0   \n",
       "4   Yes, based on the information provided in the ...                1.0   \n",
       "5   Yes, increased litter size and suckling intens...                1.0   \n",
       "6   Yes, the tPH1 A218 allele is associated with s...                1.0   \n",
       "7   Yes, according to the provided context informa...                1.0   \n",
       "8   Yes, shorter time from initiation of cooling t...                1.0   \n",
       "9   Yes, plasma levels of Galectin-9 (Gal-9) refle...                1.0   \n",
       "10  Yes, plasma MicroRNA-126-5p levels were found ...                1.0   \n",
       "11  Yes, trends in outpatient MRI show that office...                1.0   \n",
       "12  Yes, postural change during venous blood colle...                1.0   \n",
       "13  Based on the multi-decadal study conducted in ...                1.0   \n",
       "14  Yes, the direct transfer of HRPII-magnetic bea...                1.0   \n",
       "15  Yes, the evolution of clinical features in pat...                1.0   \n",
       "16  Yes, statin medications are associated with a ...                1.0   \n",
       "17  No, the negative feedback loop of cholesterol ...                1.0   \n",
       "18  Yes, obesity was identified as a factor associ...                1.0   \n",
       "19  Yes, implementation of the acute care surgery ...                1.0   \n",
       "20  Yes, perinatal variables from newborns of Ayma...                1.0   \n",
       "21  No, the prospective international cohort study...                1.0   \n",
       "22  Yes, the high rates of 23S rDNA mutations in T...                1.0   \n",
       "23  Yes, early tracheostomy in trauma patients doe...                1.0   \n",
       "24  Based on the context provided, the study evalu...                1.0   \n",
       "\n",
       "    faithfulness  sas_evaluator  \n",
       "0            1.0       0.654321  \n",
       "1            0.0       0.705631  \n",
       "2            1.0       0.835098  \n",
       "3            1.0       0.833109  \n",
       "4            1.0       0.747827  \n",
       "5            1.0       0.801956  \n",
       "6            1.0       0.920216  \n",
       "7            1.0       0.610489  \n",
       "8            1.0       0.712108  \n",
       "9            1.0       0.790772  \n",
       "10           1.0       0.734182  \n",
       "11           1.0       0.809217  \n",
       "12           1.0       0.540411  \n",
       "13           1.0       0.845297  \n",
       "14           1.0       0.663572  \n",
       "15           1.0       0.819001  \n",
       "16           1.0       0.816584  \n",
       "17           1.0       0.677808  \n",
       "18           1.0       0.730862  \n",
       "19           1.0       0.795096  \n",
       "20           1.0       0.785332  \n",
       "21           1.0       0.800335  \n",
       "22           1.0       0.677838  \n",
       "23           1.0       0.858520  \n",
       "24           1.0       0.838644  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = evaluation_result.to_pandas()\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filter down to best 3 scores for semantic answer similarity (sas_evaluator) as well as the bottom 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Please enter a value for `frac` OR `n`, not both",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m top_3 \u001b[38;5;241m=\u001b[39m results_df\u001b[38;5;241m.\u001b[39mnlargest(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msas_evaluator\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m bottom_3 \u001b[38;5;241m=\u001b[39m \u001b[43mresults_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msas_evaluator\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m pd\u001b[38;5;241m.\u001b[39mconcat([top_3, bottom_3])\n",
      "File \u001b[0;32m~/Documents/projects/AI/learning_haystack/env/lib/python3.11/site-packages/pandas/core/generic.py:6110\u001b[0m, in \u001b[0;36mNDFrame.sample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis, ignore_index)\u001b[0m\n\u001b[1;32m   6107\u001b[0m \u001b[38;5;66;03m# Process random_state argument\u001b[39;00m\n\u001b[1;32m   6108\u001b[0m rs \u001b[38;5;241m=\u001b[39m common\u001b[38;5;241m.\u001b[39mrandom_state(random_state)\n\u001b[0;32m-> 6110\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_sampling_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   6112\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m frac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/projects/AI/learning_haystack/env/lib/python3.11/site-packages/pandas/core/sample.py:94\u001b[0m, in \u001b[0;36mprocess_sampling_size\u001b[0;34m(n, frac, replace)\u001b[0m\n\u001b[1;32m     92\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m n \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m frac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease enter a value for `frac` OR `n`, not both\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m n \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Please enter a value for `frac` OR `n`, not both"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "top_3 = results_df.nlargest(3, 'sas_evaluator')\n",
    "bottom_3 = results_df.nsmallest(3, 'sas_evaluator')\n",
    "pd.concat([top_3, bottom_3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
